{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "outputId": "42b37b70-dda3-4768-d5e5-29f002623ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.4.2'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.1) (1.17.5)\n",
            "Requirement already satisfied: torchvision==0.4.2 in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2) (6.2.2)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2) (1.17.5)\n",
            "Requirement already satisfied: Pillow-SIMD in /usr/local/lib/python3.6/dist-packages (6.0.0.post0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import itertools\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "NUM_CLASSES = 7      # 101 + 1: There is am extra Background class that should be removed \n",
        "\n",
        "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 5e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "ALPHA = 3e-2\n",
        "\n",
        "LOG_FREQUENCY = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "outputId": "1e2a1fd8-95e0-417f-df09-78160ebb8628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Homework3-PACS'):\n",
        "  !git clone https://github.com/MachineLearning2020/Homework3-PACS.git\n",
        "\n",
        "PHOTO_DIR = 'Homework3-PACS/PACS/photo'\n",
        "ART_DIR = 'Homework3-PACS/PACS/art_painting'\n",
        "CARTOON_DIR = 'Homework3-PACS/PACS/cartoon'\n",
        "SKETCH_DIR = 'Homework3-PACS/PACS/sketch'\n",
        "\n",
        "# Prepare Pytorch train/test Datasets\n",
        "photo_dataset = torchvision.datasets.ImageFolder(PHOTO_DIR, transform=train_transform)\n",
        "art_dataset = torchvision.datasets.ImageFolder(ART_DIR, transform=eval_transform)\n",
        "cartoon_dataset = torchvision.datasets.ImageFolder(CARTOON_DIR, transform=eval_transform)\n",
        "sketch_dataset = torchvision.datasets.ImageFolder(SKETCH_DIR, transform=eval_transform)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Photo Dataset: {}'.format(len(photo_dataset)))\n",
        "print('Art Dataset: {}'.format(len(art_dataset)))\n",
        "print('Cartoon Dataset: {}'.format(len(cartoon_dataset)))\n",
        "print('Sketch Dataset: {}'.format(len(sketch_dataset)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Photo Dataset: 1670\n",
            "Art Dataset: 2048\n",
            "Cartoon Dataset: 2344\n",
            "Sketch Dataset: 3929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "photo_dataloader = DataLoader(photo_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "art_dataloader = DataLoader(art_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "cartoon_dataloader = DataLoader(cartoon_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "sketch_dataloader = DataLoader(sketch_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vSH_NETlF5n",
        "colab_type": "text"
      },
      "source": [
        "**AlexNet with Domain Adaptation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK7Up1velNQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torch.autograd import Function\n",
        "\n",
        "\n",
        "__all__ = ['AlexNet', 'alexnet']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    # Forwards identity\n",
        "    # Sends backward reversed gradients\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        self.dann_classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, alpha=None):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        if alpha is not None:\n",
        "            # gradient reversal layer (backward gradients will be reversed)\n",
        "            reverse_feature = ReverseLayerF.apply(x, alpha)\n",
        "            discriminator_output = self.dann_classifier(reverse_feature)\n",
        "            return discriminator_output\n",
        "        # If we don't pass alpha, we assume we are training with supervision\n",
        "        else:\n",
        "            classifier_output = self.classifier(x)\n",
        "            return classifier_output\n",
        "\n",
        "\n",
        "def alexnet(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "        \n",
        "        model.dann_classifier[1].weight.data = model.classifier[1].weight.data\n",
        "        model.dann_classifier[1].bias.data = model.classifier[1].bias.data\n",
        "        model.dann_classifier[4].weight.data = model.classifier[4].weight.data\n",
        "        model.dann_classifier[4].bias.data = model.classifier[4].bias.data\n",
        "        model.dann_classifier[6].weight.data = model.classifier[6].weight.data\n",
        "        model.dann_classifier[6].bias.data = model.classifier[6].bias.data\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_net():\n",
        "    net = alexnet(pretrained=True) # Loading AlexNet model\n",
        "    \n",
        "    # AlexNet has 1000 output neurons, corresponding to the 1000 ImageNet's classes\n",
        "    # We need 7 outputs for PACS\n",
        "    net.classifier[6] = nn.Linear(4096, NUM_CLASSES) # nn.Linear in pytorch is a fully connected layer\n",
        "    # We need 2 outputs for Domains\n",
        "    net.dann_classifier[6] = nn.Linear(4096, 2)\n",
        "    \n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMOiin2vToda",
        "colab_type": "text"
      },
      "source": [
        "**Utility Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73omtbuWTtgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss_accuracy_trend(loss_values, accuracy_values):\n",
        "    \n",
        "  plt.figure(figsize=(15,5))\n",
        "  \n",
        "  plt.subplot(1, 2, 1)\n",
        "  \n",
        "  epochs = np.arange(1, NUM_EPOCHS+1)\n",
        "\n",
        "  if loss_values[2] == None:\n",
        "    plt.plot(epochs, loss_values[0], label=\"Training\")\n",
        "    plt.plot(epochs, loss_values[1], label=\"Validation\")\n",
        "  else:\n",
        "    plt.plot(epochs, loss_values[0], label=\"Loss classifier\")\n",
        "    plt.plot(epochs, loss_values[1], label=\"Loss discriminator (source)\")\n",
        "    plt.plot(epochs, loss_values[2], label=\"Loss discriminator (target)\")\n",
        "\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "  \n",
        "  plt.subplot(1, 2, 2)\n",
        "\n",
        "  plt.plot(epochs, accuracy_values[0], label=\"Training\")\n",
        "  plt.plot(epochs, accuracy_values[1], label=\"Validation\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "def get_accuracy(model, dataLoader):\n",
        "  net = model.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  for images, labels in dataLoader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate and return Accuracy\n",
        "  return running_corrects / float(len(dataLoader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_train():\n",
        "    # Define loss function\n",
        "    criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "    # Choose parameters to optimize\n",
        "    # To access a different set of parameters, you have to access submodules of AlexNet\n",
        "    # (nn.Module objects, like AlexNet, implement the Composite Pattern)\n",
        "    # e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
        "    # e.g.: parameters of the convolutional layers: net.features.parameters() \n",
        "    parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "    # Define optimizer\n",
        "    # An optimizer updates the weights based on loss\n",
        "    # We use SGD with momentum\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "    # Define scheduler\n",
        "    # A scheduler dynamically changes learning rate\n",
        "    # The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "    return criterion, optimizer, scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "**Training functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, train_dataloader, val_dataloader=art_dataloader):\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "    best_net = None\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    train_acc = []\n",
        "    val_acc = []\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "      print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "  \n",
        "      running_loss = 0.0 \n",
        "      # Iterate over the dataset\n",
        "      for images, labels in train_dataloader:\n",
        "        # Bring data over the device of choice\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        net.train() # Sets module in training mode\n",
        "\n",
        "        optimizer.zero_grad() # Zero-ing the gradients\n",
        "        \n",
        "        # Forward pass to the network\n",
        "        outputs = net(images)\n",
        "        # Compute loss based on output and ground truth\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item() \n",
        "\n",
        "        # Log loss\n",
        "        if current_step % LOG_FREQUENCY == 0:\n",
        "          print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "        \n",
        "        # Compute gradients for each layer and update weights\n",
        "        loss.backward()  # backward pass: computes gradients\n",
        "        optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "        current_step += 1\n",
        "      \n",
        "      train_loss.append(running_loss/len(train_dataloader))  # compute average loss\n",
        "      train_acc.append(get_accuracy(net, train_dataloader)) # compute accuracy on train set\n",
        "\n",
        "      # Evaluate the model on the validation set\n",
        "      net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "      net.train(False) # Set Network to evaluation mode\n",
        "            \n",
        "      running_loss = 0.0  \n",
        "      running_corrects = 0\n",
        "      for images, labels in val_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        # Forward Pass\n",
        "        outputs = net(images)\n",
        "        \n",
        "        # Compute loss based on output and ground truth\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # Get predictions\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update Corrects\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      # Calculate Accuracy\n",
        "      accuracy = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "      print('Test Accuracy on Validation: {}'.format(accuracy))\n",
        "      \n",
        "      # Update the best model\n",
        "      if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_net = copy.deepcopy(net)\n",
        "      \n",
        "      val_acc.append(accuracy)\n",
        "      val_loss.append(running_loss/len(val_dataloader))\n",
        "            \n",
        "      # Step the scheduler\n",
        "      scheduler.step() \n",
        "\n",
        "    # Plot loss and accuracy trend\n",
        "    plot_loss_accuracy_trend([train_loss, val_loss, None], [train_acc, val_acc])\n",
        "    \n",
        "    return best_net, best_accuracy\n",
        "\n",
        "\n",
        "def train_dann(net, source_dataloader, target_dataloader):\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "    best_net = None\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    train_acc = []\n",
        "    val_acc = []\n",
        "    train_loss = []\n",
        "    train_loss0 = []\n",
        "    train_loss1 = []\n",
        "    val_loss = []\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "      print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "      \n",
        "      running_loss = 0.0 \n",
        "      running_loss0 = 0.0 \n",
        "      running_loss1 = 0.0 \n",
        "      # Iterate over the dataset\n",
        "      for i, (source_data, target_data) in enumerate(zip(source_dataloader, target_dataloader)):  \n",
        "        source_images, source_labels = source_data  \n",
        "        target_images, _ = target_data \n",
        "        \n",
        "        # Bring data over the device of choice\n",
        "        source_images = source_images.to(DEVICE)\n",
        "        source_labels = source_labels.to(DEVICE)\n",
        "        target_images = target_images.to(DEVICE)\n",
        "\n",
        "        net.train() # Sets module in training mode\n",
        "\n",
        "        optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "        # Forward pass to the network\n",
        "        outputs = net(source_images)\n",
        "        # Compute loss based on output and ground truth\n",
        "        loss = criterion(outputs, source_labels)\n",
        "        running_loss += loss.item() \n",
        "        # Compute gradients for each layer and update weights\n",
        "        loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "        # Forward pass to the network\n",
        "        outputs = net(source_images, alpha=ALPHA)\n",
        "        targets = torch.zeros(source_labels.size(0), dtype=torch.int64).to(DEVICE)\n",
        "        # Compute loss based on output and ground truth\n",
        "        discr_loss0 = criterion(outputs, targets)\n",
        "        running_loss0 += discr_loss0.item() \n",
        "        # Compute gradients for each layer and update weights\n",
        "        discr_loss0.backward()  # backward pass: computes gradients\n",
        "\n",
        "        # Forward pass to the network\n",
        "        outputs = net(target_images, alpha=ALPHA)\n",
        "        targets = torch.ones(source_labels.size(0), dtype=torch.int64).to(DEVICE)\n",
        "        # Compute loss based on output and ground truth\n",
        "        discr_loss1 = criterion(outputs, targets)\n",
        "        running_loss1 += discr_loss1.item() \n",
        "        # Compute gradients for each layer and update weights\n",
        "        discr_loss1.backward()  # backward pass: computes gradients\n",
        "\n",
        "        # Log loss\n",
        "        if current_step % LOG_FREQUENCY == 0:\n",
        "          print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "          print('Step {}, Discr_Loss0 {}'.format(current_step, discr_loss0.item()))\n",
        "          print('Step {}, Discr_Loss1 {}'.format(current_step, discr_loss1.item()))\n",
        "        \n",
        "        optimizer.step() # update weights based on accumulated gradients\n",
        "        \n",
        "        current_step += 1\n",
        "      \n",
        "      len_dataloader = min(len(source_dataloader), len(target_dataloader))\n",
        "      train_loss.append(running_loss/len_dataloader)  # compute average loss\n",
        "      train_loss0.append(running_loss0/len_dataloader)  # compute average loss\n",
        "      train_loss1.append(running_loss1/len_dataloader)  # compute average loss\n",
        "      train_acc.append(get_accuracy(net, source_dataloader)) # compute accuracy on train set\n",
        "      \n",
        "\n",
        "      # Evaluate the model on the validation set\n",
        "      net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "      net.train(False) # Set Network to evaluation mode\n",
        "            \n",
        "      running_loss = 0.0  \n",
        "      running_corrects = 0\n",
        "      for images, labels in target_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        # Forward Pass\n",
        "        outputs = net(images)\n",
        "        \n",
        "        # Compute loss based on output and ground truth\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # Get predictions\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update Corrects\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      # Calculate Accuracy\n",
        "      accuracy = running_corrects / float(len(target_dataloader.dataset))\n",
        "\n",
        "      print('Test Accuracy on Validation: {}'.format(accuracy))\n",
        "      \n",
        "      # Update the best model\n",
        "      if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_net = copy.deepcopy(net)\n",
        "      \n",
        "      val_acc.append(accuracy)\n",
        "      val_loss.append(running_loss/len(target_dataloader))\n",
        "\n",
        "\n",
        "      # Step the scheduler\n",
        "      scheduler.step() \n",
        "\n",
        "\n",
        "    # Plot loss and accuracy trend\n",
        "    plot_loss_accuracy_trend([train_loss, train_loss0, train_loss1], [train_acc, val_acc])\n",
        "    \n",
        "    return best_net, best_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "**Test function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZWh5XfOIuIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net, test_dataloader):\n",
        "  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  for images, labels in tqdm(test_dataloader):\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(art_dataset))\n",
        "  \n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qvAk_MAI9cw",
        "colab_type": "text"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "outputId": "de67d2c4-28f3-4405-d911-ac45c0478222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "DOMAIN_ADAPTATION = True  \n",
        "VALIDATION = False\n",
        "\n",
        "net = None\n",
        "\n",
        "if not DOMAIN_ADAPTATION and not VALIDATION:\n",
        "    net = prepare_net()\n",
        "    criterion, optimizer, scheduler = prepare_train()\n",
        "    # Train without domain adaptation on Photo\n",
        "    net, _ = train(net, photo_dataloader)\n",
        "\n",
        "elif DOMAIN_ADAPTATION and not VALIDATION:\n",
        "    net = prepare_net()\n",
        "    criterion, optimizer, scheduler = prepare_train()\n",
        "    # Train with domain adaptation on Photo to Art\n",
        "    net, _ = train_dann(net, photo_dataloader, art_dataloader)\n",
        "\n",
        "elif not DOMAIN_ADAPTATION and VALIDATION:\n",
        "    # Train without domain adaptation on Photo to Cartoon and on Photo to Sketch and perform grid search\n",
        "    LR_set = [5e-3, 1e-3, 1e-4]\n",
        "    BS_set = [128, 256]\n",
        "    \n",
        "    hyperparams_sets=[]\n",
        "    accuracies1 = []\n",
        "    accuracies2 = []\n",
        "\n",
        "    for i, hyperparams in enumerate(itertools.product(LR_set, BS_set)):\n",
        "      LR, BATCH_SIZE = hyperparams\n",
        "      \n",
        "      net = prepare_net()\n",
        "      criterion, optimizer, scheduler = prepare_train()\n",
        "      print('(Photo to Catoon) trying with: LR={}, BS={}'.format(LR, BATCH_SIZE))\n",
        "      # Train without domain adaptation on Photo to Cartoon\n",
        "      _, accuracy = train(net, photo_dataloader, cartoon_dataloader)\n",
        "      \n",
        "      # Save hyperparameter set and accuracy of the net\n",
        "      hyperparams_sets.append(hyperparams)\n",
        "      accuracies1.append(accuracy)\n",
        "\n",
        "      net = prepare_net()\n",
        "      criterion, optimizer, scheduler = prepare_train()\n",
        "      print('(Photo to Sketch) trying with: LR={}, BS={}'.format(LR, BATCH_SIZE))\n",
        "      # Train without domain adaptation on Photo to Sketch\n",
        "      _, accuracy = train(net, photo_dataloader, sketch_dataloader)\n",
        "      \n",
        "      # Save accuracy of the net\n",
        "      accuracies2.append(accuracy)\n",
        "\n",
        "    # Compute average of accuracies\n",
        "    avg_accuracies = (np.array(accuracies1) + np.array(accuracies2)) / 2.0\n",
        "\n",
        "    # Get the set of hyperparameter with the highest average accuracy\n",
        "    LR, BATCH_SIZE = hyperparams_sets[list(avg_accuracies).index(np.array(avg_accuracies).max())]\n",
        "    print('\\n**Best hyperparamiters: LR={}, BS={}**\\n'.format(LR, BATCH_SIZE))\n",
        "\n",
        "    net = prepare_net()\n",
        "    criterion, optimizer, scheduler = prepare_train()\n",
        "    # Train a new net with the best hyperparamiters found\n",
        "    net, _ = train(net, photo_dataloader)\n",
        "\n",
        "\n",
        "elif DOMAIN_ADAPTATION and VALIDATION:\n",
        "    # Train with domain adaptation on photo to cartoon and on photo to sketch and perform grid search\n",
        "    LR_set = [5e-3, 1e-3, 1e-4]\n",
        "    BS_set = [128, 256]\n",
        "    ALPHA_set = [0.03, 0.01, 0.001]\n",
        "    \n",
        "    hyperparams_sets=[]\n",
        "    accuracies1 = []\n",
        "    accuracies2 = []\n",
        "\n",
        "    for i, hyperparams in enumerate(itertools.product(LR_set, BS_set, ALPHA_set)):\n",
        "      LR, BATCH_SIZE, ALPHA = hyperparams\n",
        "      \n",
        "      net = prepare_net()\n",
        "      criterion, optimizer, scheduler = prepare_train()\n",
        "      print('(Photo to Catoon) trying with: LR={}, BS={}, ALPHA={}'.format(LR, BATCH_SIZE, ALPHA))\n",
        "      # Train with domain adaptation on Photo to Cartoon\n",
        "      _, accuracy = train_dann(net, photo_dataloader, cartoon_dataloader)\n",
        "      \n",
        "      # Save hyperparameter set and accuracy of the net\n",
        "      hyperparams_sets.append(hyperparams)\n",
        "      accuracies1.append(accuracy)\n",
        "\n",
        "      net = prepare_net()\n",
        "      criterion, optimizer, scheduler = prepare_train()\n",
        "      print('(Photo to Sketch) trying with: LR={}, BS={}, ALPHA={}'.format(LR, BATCH_SIZE, ALPHA))\n",
        "      # Train with domain adaptation on Photo to Sketch\n",
        "      _, accuracy = train_dann(net, photo_dataloader, sketch_dataloader)\n",
        "      \n",
        "      # Save accuracy of the net\n",
        "      accuracies2.append(accuracy)\n",
        "\n",
        "    # Compute average of accuracies\n",
        "    avg_accuracies = (np.array(accuracies1) + np.array(accuracies2)) / 2.0\n",
        "        \n",
        "    # Get the set of hyperparameter with the highest average accuracy    \n",
        "    LR, BATCH_SIZE, ALPHA = hyperparams_sets[list(avg_accuracies).index(np.array(avg_accuracies).max())]\n",
        "    print('\\n**Best hyperparamiters: LR={}, BS={}, ALPHA={}**\\n'.format(LR, BATCH_SIZE, ALPHA))\n",
        "\n",
        "    net = prepare_net()\n",
        "    criterion, optimizer, scheduler = prepare_train()\n",
        "    # Train a new net with the best hyperparamiters found\n",
        "    net, _ = train_dann(net, photo_dataloader, art_dataloader)\n",
        "\n",
        "# Test on art\n",
        "accuracy = test(net, art_dataloader)\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/20, LR = [0.005]\n",
            "Step 0, Loss 2.348292827606201\n",
            "Step 0, Discr_Loss0 1.2917776107788086\n",
            "Step 0, Discr_Loss1 0.4774324595928192\n",
            "Test Accuracy on Validation: 0.45361328125\n",
            "Starting epoch 2/20, LR = [0.005]\n",
            "Step 10, Loss 0.0992569550871849\n",
            "Step 10, Discr_Loss0 0.19273227453231812\n",
            "Step 10, Discr_Loss1 0.2265956699848175\n",
            "Test Accuracy on Validation: 0.46875\n",
            "Starting epoch 3/20, LR = [0.005]\n",
            "Test Accuracy on Validation: 0.4697265625\n",
            "Starting epoch 4/20, LR = [0.005]\n",
            "Step 20, Loss 0.09644267708063126\n",
            "Step 20, Discr_Loss0 0.24127832055091858\n",
            "Step 20, Discr_Loss1 0.0759207233786583\n",
            "Test Accuracy on Validation: 0.50634765625\n",
            "Starting epoch 5/20, LR = [0.005]\n",
            "Test Accuracy on Validation: 0.53173828125\n",
            "Starting epoch 6/20, LR = [0.005]\n",
            "Step 30, Loss 0.035607703030109406\n",
            "Step 30, Discr_Loss0 0.07436894625425339\n",
            "Step 30, Discr_Loss1 0.148408904671669\n",
            "Test Accuracy on Validation: 0.50439453125\n",
            "Starting epoch 7/20, LR = [0.005]\n",
            "Step 40, Loss 0.009503103792667389\n",
            "Step 40, Discr_Loss0 0.04013651981949806\n",
            "Step 40, Discr_Loss1 0.1675363928079605\n",
            "Test Accuracy on Validation: 0.52783203125\n",
            "Starting epoch 8/20, LR = [0.005]\n",
            "Test Accuracy on Validation: 0.5\n",
            "Starting epoch 9/20, LR = [0.005]\n",
            "Step 50, Loss 0.010914398357272148\n",
            "Step 50, Discr_Loss0 0.028601353988051414\n",
            "Step 50, Discr_Loss1 0.029017334803938866\n",
            "Test Accuracy on Validation: 0.4931640625\n",
            "Starting epoch 10/20, LR = [0.005]\n",
            "Test Accuracy on Validation: 0.5029296875\n",
            "Starting epoch 11/20, LR = [0.005]\n",
            "Step 60, Loss 0.005910059437155724\n",
            "Step 60, Discr_Loss0 0.02153800055384636\n",
            "Step 60, Discr_Loss1 0.015948697924613953\n",
            "Test Accuracy on Validation: 0.50341796875\n",
            "Starting epoch 12/20, LR = [0.005]\n",
            "Step 70, Loss 0.004635762423276901\n",
            "Step 70, Discr_Loss0 0.027672700583934784\n",
            "Step 70, Discr_Loss1 0.015026472508907318\n",
            "Test Accuracy on Validation: 0.50439453125\n",
            "Starting epoch 13/20, LR = [0.005]\n",
            "Test Accuracy on Validation: 0.49560546875\n",
            "Starting epoch 14/20, LR = [0.005]\n",
            "Step 80, Loss 0.0019997451454401016\n",
            "Step 80, Discr_Loss0 0.0404658317565918\n",
            "Step 80, Discr_Loss1 0.023150989785790443\n",
            "Test Accuracy on Validation: 0.5048828125\n",
            "Starting epoch 15/20, LR = [0.005]\n",
            "Test Accuracy on Validation: 0.505859375\n",
            "Starting epoch 16/20, LR = [0.005]\n",
            "Step 90, Loss 0.002096058800816536\n",
            "Step 90, Discr_Loss0 0.014601560309529305\n",
            "Step 90, Discr_Loss1 0.01930812932550907\n",
            "Test Accuracy on Validation: 0.50732421875\n",
            "Starting epoch 17/20, LR = [0.005]\n",
            "Step 100, Loss 0.0007830038666725159\n",
            "Step 100, Discr_Loss0 0.009568117558956146\n",
            "Step 100, Discr_Loss1 0.05060780420899391\n",
            "Test Accuracy on Validation: 0.51611328125\n",
            "Starting epoch 18/20, LR = [0.005]\n",
            "Test Accuracy on Validation: 0.52783203125\n",
            "Starting epoch 19/20, LR = [0.005]\n",
            "Step 110, Loss 0.0007032155990600586\n",
            "Step 110, Discr_Loss0 0.014806403778493404\n",
            "Step 110, Discr_Loss1 0.020113224163651466\n",
            "Test Accuracy on Validation: 0.5185546875\n",
            "Starting epoch 20/20, LR = [0.005]\n",
            "Test Accuracy on Validation: 0.50732421875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFgCAYAAABNIolGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:05<00:00,  1.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.53173828125\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}